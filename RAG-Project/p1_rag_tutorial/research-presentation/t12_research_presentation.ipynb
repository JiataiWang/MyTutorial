{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_TRACING\"] = \"false\"\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['OPENAI_API_KEY'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/v4c_6cv52lgdw4xwjdrl8z8c0000gn/T/ipykernel_31309/480133866.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，写入向量条目数：3416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，具有大量、高速、多样、价值密度低等特点。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from langchain import hub\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "DATA_DIR = Path(\"/Users/titus.w/Code/MyProfile/GitHub/RAG-Project/p1_rag_tutorial/research-presentation/\")          # 三个文件所在目录\n",
    "files = [\"data1.xlsx\", \"data2.xlsx\", \"data3.xlsx\"]\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    file_path = DATA_DIR / f\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(file_path)\n",
    "    \n",
    "\n",
    "    xl = pd.ExcelFile(file_path)\n",
    "    for sheet in xl.sheet_names:\n",
    "        df = xl.parse(sheet)\n",
    "        df[\"__source_file__\"] = f\"{f}:{sheet}\"\n",
    "        dfs.append(df)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "clean_df = (\n",
    "    raw_df\n",
    "    .dropna(how=\"all\")\n",
    "    .applymap(lambda x: str(x).strip() if pd.notna(x) else x)\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "documents = []\n",
    "for idx, row in clean_df.iterrows():\n",
    "    content = f\"问：{row['问题']}\\n答：{row['答案']}\\n来源：{row['__source_file__']}\"\n",
    "    metadata = {\n",
    "        \"row_index\": int(idx),\n",
    "        \"source\": row[\"__source_file__\"],\n",
    "    }\n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "print(f\"处理完成，写入向量条目数：{vectorstore._collection.count()}\")\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "rag_chain.invoke(\"什么是大数据?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题1：大数据的价值体现在哪些方面？\n",
      "回答1：为企业提供决策支持、优化业务流程、发现新的商业机会、提升客户体验等。\n",
      "来源：data1.xlsx:Sheet1\n",
      "------------------------------------------------------------\n",
      "问题2：大数据分析如何帮助企业进行决策？\n",
      "回答2：大数据分析为企业提供了强大的数据支持，使决策者能够基于实证数据发现新的商业机会、评估潜在风险，并优化业务流程。这种数据驱动的决策模式能够提高企业的竞争力和市场适应性。\n",
      "来源：data1.xlsx:Sheet1\n",
      "------------------------------------------------------------\n",
      "问题3：什么是大数据？\n",
      "回答3：答案：大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，具有大量、高速、多样、价值密度低等特点。\n",
      "来源：data1.xlsx:Sheet1\n",
      "------------------------------------------------------------\n",
      "问题4：大数据在行业或领域有哪些应用情况？\n",
      "回答4：大数据无处不在，包括金融、汽车、餐饮、电信、能源、体育和娱乐等在内的社会各行各业都已经融入了大数据的印迹，下表是大数据在各个领域的应用情况。任答两个都可以。\n",
      "来源：data1.xlsx:Sheet1\n",
      "------------------------------------------------------------\n",
      "问题5：大数据对社会发展的影响有哪些？\n",
      "回答5：推动科技创新、提高决策效率、促进经济发展等。\n",
      "来源：data1.xlsx:Sheet1\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，具有大量、高速、多样、价值密度低等特点。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"您是一个AI语言模型助手。您的任务是生成五个不同版本的用户问题，以从向量数据库中检索相关文档。\n",
    "通过从多个角度生成用户问题，您的目标是帮助用户克服基于距离的相似性搜索的一些局限性。\n",
    "请提供这些替代问题，每个问题之间用换行符分隔。 初始问题: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"什么是大数据?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)\n",
    "def pretty_print_docs(docs):\n",
    "    \"\"\"\n",
    "    将 LangChain Document 列表按“问题n / 回答n”格式打印\n",
    "    \"\"\"\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        # 按换行切分“问：…\\n答：…”\n",
    "        parts = doc.page_content.split(\"\\n\", 1)\n",
    "        question = parts[0].replace(\"问：\", \"\").strip() if parts else \"\"\n",
    "        answer   = parts[1].replace(\"答：\", \"\").strip() if len(parts) > 1 else \"\"\n",
    "        \n",
    "        print(f\"问题{i}：{question}\")\n",
    "        print(f\"回答{i}：{answer}\")\n",
    "        print(\"-\" * 60)\n",
    "pretty_print_docs(docs)\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG-Fusion（Re-ranking）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题1：大数据技术包括哪些主要组成部分？\n",
      "回答1：数据采集：通过传感器、网络爬虫、日志文件等多种方式收集数据。\n",
      "数据存储：利用分布式文件系统（如HDFS）、分布式数据库等技术存储海量数据。\n",
      "数据处理：对数据进行清洗、转换、规约等操作，提高数据质量。\n",
      "数据分析：运用统计分析、机器学习、数据挖掘等技术从数据中提取有价值的信息。\n",
      "数据可视化：将数据以直观、易懂的形式展示出来，帮助用户理解数据中的规律和趋势。\n",
      "来源：data1.xlsx:Sheet1\n",
      "相似度分数：0.1301\n",
      "------------------------------------------------------------\n",
      "问题2：什么是大数据？\n",
      "回答2：大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，具有大量（Volume）、高速（Velocity）、多样（Variety）和价值密度低（Value）等特点。这些数据集合的规模巨大，数据类型复杂多样，包括结构化、半结构化和非结构化数据，处理速度要求高，且其中蕴含的价值需要通过高级分析技术才能提取出来。\n",
      "来源：data1.xlsx:Sheet1\n",
      "相似度分数：0.0651\n",
      "------------------------------------------------------------\n",
      "问题3：大数据在行业或领域有哪些应用情况？\n",
      "回答3：大数据无处不在，包括金融、汽车、餐饮、电信、能源、体育和娱乐等在内的社会各行各业都已经融入了大数据的印迹，下表是大数据在各个领域的应用情况。任答两个都可以。\n",
      "来源：data1.xlsx:Sheet1\n",
      "相似度分数：0.0651\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，具有大量（Volume）、高速（Velocity）、多样（Variety）和价值密度低（Value）等特点。'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG-Fusion: Related\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"您是一个有用的助手，可以根据单个输入查询生成多个搜索查询。 \\n\n",
    "生成多个与之相关的搜索查询: {question} \\n\n",
    "输出（4个查询）:\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)\n",
    "def pretty_print(results):\n",
    "    \"\"\"\n",
    "    支持两种输入格式：\n",
    "      1. [Document, Document, ...]\n",
    "      2. [(Document, score), (Document, score), ...]\n",
    "    按“问题n / 回答n”友好打印；若包含 score 也一起显示。\n",
    "    \"\"\"\n",
    "    for i, item in enumerate(results, 1):\n",
    "        # 判断是否含相似度分数\n",
    "        if isinstance(item, tuple):\n",
    "            doc, score = item       # Tuple: (Document, score)\n",
    "        else:\n",
    "            doc, score = item, None # 只有 Document\n",
    "        \n",
    "        # 解析问答文本\n",
    "        parts = doc.page_content.split(\"\\n\", 1)\n",
    "        question = parts[0].replace(\"问：\", \"\").strip() if parts else \"\"\n",
    "        answer   = parts[1].replace(\"答：\", \"\").strip() if len(parts) > 1 else \"\"\n",
    "        \n",
    "        # 打印\n",
    "        print(f\"问题{i}：{question}\")\n",
    "        print(f\"回答{i}：{answer}\")\n",
    "        if score is not None:\n",
    "            print(f\"相似度分数：{score:.4f}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# 示例调用：results 即你给出的列表\n",
    "pretty_print(docs)\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 大数据是如何应用于商业和科学领域的？', '2. 大数据如何影响人们的日常生活和决策？', '3. 大数据的发展历史和未来趋势是什么？']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"您是一个有帮助的助手，可以生成与输入问题相关的多个子问题。\\n\n",
    "目标是将输入分解为一组可以单独回答的子问题/子问题。 \\n\n",
    "生成多个与之相关的搜索查询: {question} \\n\n",
    "输出（3个查询）:\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Run\n",
    "question = \"什么是大数据??\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大数据的发展历史可以追溯到20世纪90年代，随着互联网的普及和数字化技术的发展，数据量急剧增加，从而催生了大数据概念的提出。随着时间的推移，大数据技术不断发展，包括数据采集、存储、处理和分析等方面的技术不断完善，大数据分析工具和平台也不断涌现，为企业和科学研究提供了更多的数据支持和洞察力。\n",
      "\n",
      "未来，大数据的发展趋势包括人工智能与大数据的融合、实时数据分析和边缘计算等。人工智能的发展将进一步提升大数据分析的智能化水平，实时数据分析将帮助企业更快速地做出决策和应对市场变化，而边缘计算则将使数据处理更加高效和便捷。这些趋势将进一步推动大数据技术的发展，为商业和科学领域带来更多的创新和机遇。\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "template = \"\"\"这里是你需要回答的问题:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "这里是所有可用的背景问题 + 答案对。:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "这里是与问题相关的额外背景信息。: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "使用上述上下文和任何背景问题 + 答案对来回答问题: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
    "answer\n",
    "from textwrap import dedent\n",
    "def pretty_print_answer(text: str, as_markdown: bool = False):\n",
    "    formatted = dedent(text.replace(\"\\\\n\", \"\\n\")).strip()\n",
    "    if as_markdown:\n",
    "        display(Markdown(formatted))\n",
    "    else:\n",
    "        print(formatted)\n",
    "\n",
    "# 普通终端/Notebook 输出\n",
    "pretty_print_answer(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑路由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大数据知识库'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "\n",
    "    datasource: Literal[\"大数据知识库\", \"医学知识库\", \"法律知识库\"] = Field(\n",
    "        ...,\n",
    "        description=\"根据用户问题选择哪个数据源对回答他们的问题最相关。\",\n",
    "    )\n",
    "\n",
    "# LLM with function call \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt \n",
    "system = \"\"\"您是将用户问题路由到适当数据源的专家。\n",
    "根据问题所涉及的编程语言，将其路由到相关的数据源。\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router \n",
    "router = prompt | structured_llm\n",
    "question = \"\"\"为什么Hadoop技术非常重要？\n",
    "\"\"\"\n",
    "result = router.invoke({\"question\": question})\n",
    "result\n",
    "result.datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语义路由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "大数据是指海量、多样化、高速产生的数据集合。这些数据量大到传统数据处理工具难以处理，但通过大数据技术和工具可以进行有效的分析和挖掘，以获取有价值的信息和洞察。\n"
     ]
    }
   ],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Two prompts\n",
    "bigdata_template = \"\"\"你是一位非常聪明的大数据专家。 \\\n",
    "你擅长以简洁易懂的方式回答有关大数据的问题。 \\\n",
    "当你不知道问题的答案时，你承认你不知道。\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"你是一个非常优秀的数学家。你擅长回答数学问题。 \\\n",
    "你之所以这么厉害，是因为你能够将复杂的问题分解成各个组成部分， \\\n",
    "回答各个组成部分，然后将它们结合起来回答更广泛的问题。\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "# Embed prompts\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [bigdata_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Route question to prompt \n",
    "def prompt_router(input):\n",
    "    # Embed question\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    # Compute similarity\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    # Chosen prompt \n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"什么是大数据?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Idex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gt/v4c_6cv52lgdw4xwjdrl8z8c0000gn/T/ipykernel_31309/3433576282.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw_df = raw_df.applymap(lambda x: str(x).strip() if pd.notna(x) else x).drop_duplicates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文档数：846\n",
      "--------------------------------------------------------------------------------\n",
      "切分后文档块数：851\n",
      "嵌入维度： 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/titus.w/opt/anaconda3/envs/rag3.9/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 27599 (\\N{CJK UNIFIED IDEOGRAPH-6BCF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/titus.w/opt/anaconda3/envs/rag3.9/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 31751 (\\N{CJK UNIFIED IDEOGRAPH-7C07}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/titus.w/opt/anaconda3/envs/rag3.9/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 25991 (\\N{CJK UNIFIED IDEOGRAPH-6587}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/titus.w/opt/anaconda3/envs/rag3.9/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 26723 (\\N{CJK UNIFIED IDEOGRAPH-6863}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/titus.w/opt/anaconda3/envs/rag3.9/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/titus.w/opt/anaconda3/envs/rag3.9/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "原始检索文档示例：\n",
      "[Doc 1] 问：什么是大数据？\n",
      "答：大数据是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，具有大量（Volume）、高速（Velocity）、多样（Variety）和价值密度低（Value）等特点。这些数据集合的规模巨大，数据类型…  (data1.xlsx:Sheet1)\n",
      "[Doc 2] 问：大数据的“4V”特性是什么？\n",
      "答：Volume（大量）、Velocity（高速）、Variety（多样）、Value（价值密度低），共同定义了数据的规模、实时性、类型广泛性和信息价值。…  (data1.xlsx:Sheet1)\n",
      "[Doc 3] 问：大数据与传统数据的主要区别是什么？\n",
      "答：规模：大数据的规模远大于传统数据，可以达到PB级甚至EB级。\n",
      "类型：大数据类型多样，包括结构化、半结构化和非结构化数据，而传统数据主要是结构化数据。\n",
      "处理速度：大数据要求极高的处理速度，以实现实时…  (data1.xlsx:Sheet1)\n",
      "[Doc 4] 问：列举三个常见的大数据来源。\n",
      "答：大数据采集可以通过多种方法实现，包括但不限于传感器采集、网络爬虫、日志文件采集以及数据库抽取。这些方法使我们能够从各种来源收集所需的数据。…  (data1.xlsx:Sheet1)\n",
      "[Doc 5] 问：大数据技术包括哪些主要组成部分？\n",
      "答：数据采集：通过传感器、网络爬虫、日志文件等多种方式收集数据。\n",
      "数据存储：利用分布式文件系统（如HDFS）、分布式数据库等技术存储海量数据。\n",
      "数据处理：对数据进行清洗、转换、规约等操作，提高数据质量。…  (data1.xlsx:Sheet1)\n",
      "\n",
      "聚类后文档分布：\n",
      "\n",
      "=== 簇 0 | 文档数 77 ===\n",
      "- 问：简述Hadoop和谷歌的MapReduce、GFS等技术之间的关系。 ...\n",
      "- 问：简述在 Reduce 端的 Shuffle 过程。 ...\n",
      "- 问：简述什么是Combiner函数，它的主要作用。 ...\n",
      "\n",
      "=== 簇 1 | 文档数 54 ===\n",
      "- 问：什么是数据仓库？ ...\n",
      "- 问：如何确保大数据采集的准确性？ ...\n",
      "- 问：大数据采集过程中可能遇到哪些问题？如何解决？ ...\n",
      "\n",
      "=== 簇 2 | 文档数 70 ===\n",
      "- 问：简述UMP系统如何实现容灾的。 ...\n",
      "- 问：简述UMP系统中主从切换的过程。 ...\n",
      "- 问：简述UMP系统宕机后的主库在进行恢复处理后需要再次上线的过程。 ...\n",
      "\n",
      "=== 簇 3 | 文档数 46 ===\n",
      "- 问：HDFS的常用Shell命令有哪些？ ...\n",
      "- 问：MapReduce的编程实践中，如何查看运行结果？ ...\n",
      "- 问：HDFS客户端的命令行界面有哪些特点？ ...\n",
      "\n",
      "=== 簇 4 | 文档数 184 ===\n",
      "- 问：Hadoop 分布式文件系统（HDFS）的特点有哪些？ ...\n",
      "- 问：简述HDFS采用抽象的块概念可以带来的好处。 ...\n",
      "- 问：简述HDFS体系结构。 ...\n",
      "\n",
      "=== 簇 5 | 文档数 129 ===\n",
      "- 问：请说出两种大数据存储技术。 ...\n",
      "- 问：列式存储和行式存储的区别是什么？ ...\n",
      "- 问：NoSQL 数据库与传统 SQL 数据库的区别是什么？ ...\n",
      "\n",
      "=== 簇 6 | 文档数 65 ===\n",
      "- 问：简述Hive HA主要解决的问题。 ...\n",
      "- 问：简述Hive HA基本原理。 ...\n",
      "- 问：Hadoop是什么？ ...\n",
      "\n",
      "=== 簇 7 | 文档数 113 ===\n",
      "- 问：什么是大数据？ ...\n",
      "- 问：大数据与传统数据的主要区别是什么？ ...\n",
      "- 问：列举三个常见的大数据来源。 ...\n",
      "\n",
      "=== 簇 8 | 文档数 50 ===\n",
      "- 问：大数据的“4V”特性是什么？ ...\n",
      "- 问：什么是数据可视化？ ...\n",
      "- 问：数据可视化的目的是什么？ ...\n",
      "\n",
      "=== 簇 9 | 文档数 63 ===\n",
      "- 问：简述Spark的主要特点。 ...\n",
      "- 问：简述相比于Hadoop MapReduce，Spark的主要优点。 ...\n",
      "- 问：简述什么是Spark Core。 ...\n",
      "\n",
      "每个簇的总结：\n",
      "簇 0：主题：MapReduce技术及其应用\n",
      "关键信息：Hadoop是基于谷歌技术的开源实现，包括HDFS和MapReduce；Reduce端的Shuffle过程是数据传输和处理的关键步骤；Combiner函数用于局部合并减少数据传输；Partitioner函数用于分组数据给Reduce任务；Wordcount程序执行过程包括Map和Reduce任务；MapReduce实现关系的选择、并、交、差运算；编写MapReduce程序的主要步骤。\n",
      "簇 1：主题：数据仓库、大数据采集准确性、数据采集安全性、大数据存储优势、云存储作用、数据压缩意义、选择存储方案。\n",
      "关键信息：数据仓库存储历史数据支持分析；确保大数据采集准确性需数据源质量控制；数据采集安全需加密、访问控制；大数据存储优势包括高可靠性、低成本；云存储提供灵活资源；数据压缩节省空间提高效率；选择存储方案需考虑数据规模、类型、访问模式和成本。\n",
      "簇 2：UMP系统实现容灾、主从切换、读写分离、分库分表等功能，保证系统高可用性和数据一致性。ApplicationMaster负责资源调度和任务监控。YARN目标是实现一个集群多个框架的资源共享和弹性收缩。Pig是Hadoop组件，通过Pig Latin脚本实现复杂数据分析，自动转换为MapReduce作业，简化编程。\n",
      "簇 3：主题：HDFS Shell命令和MapReduce编程实践\n",
      "关键信息：HDFS常用Shell命令包括-ls、-mkdir、-cat、-copyFromLocal；MapReduce查看结果通过访问HDFS输出目录；HDFS客户端命令行界面类似Shell；HDFS读写数据的代码示例；HDFS Shell命令执行需要安全认证。\n",
      "簇 4：HDFS是Hadoop分布式文件系统，具有高可靠性、高扩展性、高性能、低成本、易管理、支持多数据类型、灵活访问和数据安全等特点。采用抽象块概念简化系统设计，体系结构包括名称节点和数据节点，但唯一名称节点会带来局限性。数据读取通过机架ID确定副本位置，处理名称节点故障可通过备份和第二名称节点恢复。HDFS联邦相对于HDFS1.0具有更好的扩展性、性能和隔离性。\n",
      "簇 5：文档主题为大数据存储技术，重点介绍了Hadoop分布式文件系统（HDFS）、NoSQL数据库、列式存储、行式存储、内存数据库、HBase与传统数据库的区别、HBase中行、列族、列限定符的概念及访问方式。总结了各种存储技术的特点和适用场景。\n",
      "簇 6：主题：Hive HA解决Hive不稳定问题，基本原理和Hadoop概述。\n",
      "关键信息：Hive HA通过HAProxy管理多个Hive实例，提供统一访问接口；Hadoop是Apache软件基金会的开源分布式计算平台，最初由Doug Cutting开发；Hadoop核心组件为HDFS和MapReduce，支持多平台，具有高可靠性和可扩展性。\n",
      "簇 7：数据等，用于支撑学术研究和科研工作。\n",
      "簇 8：主题：数据可视化在大数据分析中的重要性\n",
      "关键信息：数据可视化通过图形化展示数据，帮助用户理解数据、发现模式和趋势，支持决策制定。常见工具有Tableau、PowerBI、Echarts，选择合适的可视化方式根据数据类型和分析目的。交互式数据可视化提高数据分析效率和深度，地图可视化在GIS、物流、城市规划等领域有广泛应用。\n",
      "簇 9：如map、filter、groupBy等），可以在不同节点上并行执行，进一步提高了计算效率。\n",
      "（2）内存计算。Spark 支持将数据集存储在内存中，可以避免频繁的磁盘读写操作，提高数据处理速度。同时，Spark 的内存管理机制能够有效地利用内存空间，提高数据处理的效率。\n",
      "（3）任务调度优化。Spark 使用基于 DAG 的任务调度执行引擎，可以将任务分解成多个阶段，每个阶段中包含多个任务，通过任务调度器将任务分发给各个工作节点上的 Executor 并行执行，充分利用集群的计算资源，提高数据处理和计算的效率。\n",
      "\n",
      "🏁 主题汇总（出现次数降序）：\n",
      "1 × 主题：MapReduce技术及其应用\n",
      "关键信息：Hadoop是基于谷歌技术的开源实现，包括HDFS和MapReduce；Reduce端的Shuffle过程是数据传输和处理的关键步骤；Combiner函数用于局部合并减少数据传输；Partitioner函数用于分组数据给Reduce任务；Wordcount程序执行过程包括Map和Reduce任务；MapReduce实现关系的选择、并、交、差运算；编写MapReduce程序的主要步骤。\n",
      "1 × 主题：数据仓库、大数据采集准确性、数据采集安全性、大数据存储优势、云存储作用、数据压缩意义、选择存储方案。\n",
      "关键信息：数据仓库存储历史数据支持分析；确保大数据采集准确性需数据源质量控制；数据采集安全需加密、访问控制；大数据存储优势包括高可靠性、低成本；云存储提供灵活资源；数据压缩节省空间提高效率；选择存储方案需考虑数据规模、类型、访问模式和成本。\n",
      "1 × UMP系统实现容灾、主从切换、读写分离、分库分表等功能，保证系统高可用性和数据一致性。ApplicationMaster负责资源调度和任务监控。YARN目标是实现一个集群多个框架的资源共享和弹性收缩。Pig是Hadoop组件，通过Pig Latin脚本实现复杂数据分析，自动转换为MapReduce作业，简化编程。\n",
      "1 × 主题：HDFS Shell命令和MapReduce编程实践\n",
      "关键信息：HDFS常用Shell命令包括-ls、-mkdir、-cat、-copyFromLocal；MapReduce查看结果通过访问HDFS输出目录；HDFS客户端命令行界面类似Shell；HDFS读写数据的代码示例；HDFS Shell命令执行需要安全认证。\n",
      "1 × HDFS是Hadoop分布式文件系统，具有高可靠性、高扩展性、高性能、低成本、易管理、支持多数据类型、灵活访问和数据安全等特点。采用抽象块概念简化系统设计，体系结构包括名称节点和数据节点，但唯一名称节点会带来局限性。数据读取通过机架ID确定副本位置，处理名称节点故障可通过备份和第二名称节点恢复。HDFS联邦相对于HDFS1.0具有更好的扩展性、性能和隔离性。\n",
      "1 × 文档主题为大数据存储技术，重点介绍了Hadoop分布式文件系统（HDFS）、NoSQL数据库、列式存储、行式存储、内存数据库、HBase与传统数据库的区别、HBase中行、列族、列限定符的概念及访问方式。总结了各种存储技术的特点和适用场景。\n",
      "1 × 主题：Hive HA解决Hive不稳定问题，基本原理和Hadoop概述。\n",
      "关键信息：Hive HA通过HAProxy管理多个Hive实例，提供统一访问接口；Hadoop是Apache软件基金会的开源分布式计算平台，最初由Doug Cutting开发；Hadoop核心组件为HDFS和MapReduce，支持多平台，具有高可靠性和可扩展性。\n",
      "1 × 数据等，用于支撑学术研究和科研工作。\n",
      "1 × 主题：数据可视化在大数据分析中的重要性\n",
      "关键信息：数据可视化通过图形化展示数据，帮助用户理解数据、发现模式和趋势，支持决策制定。常见工具有Tableau、PowerBI、Echarts，选择合适的可视化方式根据数据类型和分析目的。交互式数据可视化提高数据分析效率和深度，地图可视化在GIS、物流、城市规划等领域有广泛应用。\n",
      "1 × 如map、filter、groupBy等），可以在不同节点上并行执行，进一步提高了计算效率。\n",
      "（2）内存计算。Spark 支持将数据集存储在内存中，可以避免频繁的磁盘读写操作，提高数据处理速度。同时，Spark 的内存管理机制能够有效地利用内存空间，提高数据处理的效率。\n",
      "（3）任务调度优化。Spark 使用基于 DAG 的任务调度执行引擎，可以将任务分解成多个阶段，每个阶段中包含多个任务，通过任务调度器将任务分发给各个工作节点上的 Executor 并行执行，充分利用集群的计算资源，提高数据处理和计算的效率。\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "DATA_DIR = Path(\"/Users/titus.w/Code/MyProfile/GitHub/RAG-Project/p1_rag_tutorial/research-presentation/\")   # 调整为实际路径\n",
    "excel_files = [\"data1.xlsx\", \"data2.xlsx\", \"data3.xlsx\"]\n",
    "\n",
    "dfs = []\n",
    "for fn in excel_files:\n",
    "    xl = pd.ExcelFile(DATA_DIR / fn)\n",
    "    for sheet in xl.sheet_names:\n",
    "        df = xl.parse(sheet)\n",
    "        df[\"__source__\"] = f\"{fn}:{sheet}\"\n",
    "        dfs.append(df)\n",
    "\n",
    "raw_df = pd.concat(dfs, ignore_index=True).dropna(how=\"all\")\n",
    "raw_df = raw_df.applymap(lambda x: str(x).strip() if pd.notna(x) else x).drop_duplicates()\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"问：{row['问题']}\\n答：{row['答案']}\",\n",
    "        metadata={\"source\": row[\"__source__\"], \"row\": int(idx)},\n",
    "    )\n",
    "    for idx, row in raw_df.iterrows()\n",
    "]\n",
    "\n",
    "print(f\"原始文档数：{len(documents)}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(documents)\n",
    "print(f\"切分后文档块数：{len(chunks)}\")\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "emb = OpenAIEmbeddings()\n",
    "emb_vectors = np.array(emb.embed_documents([c.page_content for c in chunks]))\n",
    "print(\"嵌入维度：\", emb_vectors.shape[1])\n",
    "\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "k = max(2, min(10, int(sqrt(len(chunks) / 2))))\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "labels = kmeans.fit_predict(emb_vectors)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title(\"每簇文档数量\")\n",
    "plt.xlabel(\"Cluster ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n原始检索文档示例：\")\n",
    "for i, doc in enumerate(documents[:5], 1):\n",
    "    print(f\"[Doc {i}] {doc.page_content[:120]}…  ({doc.metadata['source']})\")\n",
    "\n",
    "\n",
    "cluster_docs = {cid: [] for cid in unique}\n",
    "for doc, cid in zip(chunks, labels):\n",
    "    cluster_docs[cid].append(doc)\n",
    "\n",
    "print(\"\\n聚类后文档分布：\")\n",
    "for cid in sorted(cluster_docs):\n",
    "    print(f\"\\n=== 簇 {cid} | 文档数 {len(cluster_docs[cid])} ===\")\n",
    "    for d in cluster_docs[cid][:3]:  # 每簇仅示例打印 3 条\n",
    "        print(\"-\", d.page_content.split(\"\\n\")[0][:80], \"...\")\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"请用中文概括以下文档片段的主要主题和关键信息，不超过 80 字：\n",
    "    {texts}\"\"\"\n",
    ")\n",
    "\n",
    "cluster_summaries = {}\n",
    "for cid, docs_in_cluster in cluster_docs.items():\n",
    "    # 取前 few 条拼接文本（太长会超 context，可自行调整数量）\n",
    "    sample_text = \"\\n\\n\".join(d.page_content[:400] for d in docs_in_cluster[:8])\n",
    "    resp = llm.predict(summary_prompt.format(texts=sample_text))\n",
    "    cluster_summaries[cid] = resp.strip()\n",
    "\n",
    "\n",
    "print(\"\\n每个簇的总结：\")\n",
    "for cid, summ in sorted(cluster_summaries.items()):\n",
    "    print(f\"簇 {cid}：{summ}\")\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "final_topics = Counter(cluster_summaries.values()).most_common()\n",
    "print(\"\\n🏁 主题汇总（出现次数降序）：\")\n",
    "for topic, freq in final_topics:\n",
    "    print(f\"{freq} × {topic}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
